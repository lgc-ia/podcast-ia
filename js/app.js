document.addEventListener("DOMContentLoaded", (e) => {
    e.preventDefault();

    const promptInput = document.getElementById('promptInput');
    const sendBtn = document.getElementById('sendBtn');
    const clearBtn = document.getElementById('clearBtn');
    const btnText = sendBtn.querySelector('span');
    const btnLoader = document.getElementById('btnLoader');
    const responseOutput = document.getElementById('responseOutput');
    const footerYear = document.querySelector('.footer-year');
    if (footerYear) {
        footerYear.textContent = new Date().getFullYear();
    }
    

    // --- CONFIGURATION ---

    // ‚ö†Ô∏è ATTENTION : En production, ne jamais laisser une cl√© API c√¥t√© client.
    const API_KEY = "sk-553d888c4f9b4bf8af4eedd580629f3d";
    const API_URL = "https://api.deepseek.com/chat/completions";

    // TTS : endpoints Piper HTTP
    // Tu peux inverser les URLs si tu veux H√¥te=femme, Invit√©=homme.
    const TTS_HOST_URL = "https://ttsh.lagrandeclasse.fr/"; // H√¥te -> femme
    const TTS_GUEST_URL = "https://ttsf.lagrandeclasse.fr/"; // Invit√© -> homme 

    let isRunning = false;            // Pour arr√™ter le podcast
    let conversationHistory = [];     // Historique pour le LLM
    let currentAudio = null;          // Audio en cours de lecture
    let currentAudioUrl = null;       // URL √† lib√©rer pour l'audio courant
    let currentAudioResolver = null;  // Permet de r√©soudre la promesse de lecture si on stoppe manuellement

    // Stoppe proprement le son en cours (si pr√©sent) et r√©sout la promesse rattach√©e
    const stopAudioPlayback = () => {
        if (currentAudio) {
            currentAudio.onended = null;
            currentAudio.onerror = null;
            currentAudio.onpause = null;
            currentAudio.pause();
            currentAudio.currentTime = 0;
        }

        if (currentAudioUrl) {
            URL.revokeObjectURL(currentAudioUrl);
        }

        currentAudio = null;
        currentAudioUrl = null;

        if (currentAudioResolver) {
            const resolver = currentAudioResolver;
            currentAudioResolver = null;
            resolver();
        }
    };

    // --- FONCTIONS IA ---

    // Appel DeepSeek (compatible OpenAI)
    const callDeepSeek = async (messages) => {
        try {
            const response = await fetch(API_URL, {
                method: "POST",
                headers: {
                    "Content-Type": "application/json",
                    "Authorization": `Bearer ${API_KEY}`
                },
                body: JSON.stringify({
                    model: "deepseek-chat",
                    messages: messages,
                    temperature: 0.9,
                    // max_tokens: 300
                })
            });

            if (!response.ok) {
                throw new Error(`Erreur API: ${response.status}`);
            }

            const data = await response.json();
            return data.choices[0].message.content;
        } catch (error) {
            console.error("Erreur lors de l'appel DeepSeek:", error);
            return null;
        }
    };

    // --- FONCTIONS TTS ---

    // R√©cup√®re l‚ÄôURL de base TTS en fonction de l‚Äôinterlocuteur
    const getTTSBaseUrlForSpeaker = (speaker) => {
        if (speaker === "H√¥te") return TTS_HOST_URL;
        if (speaker === "Invit√©") return TTS_GUEST_URL;
        // fallback : H√¥te
        return TTS_HOST_URL;
    };

    // Appelle le TTS et joue le son, puis r√©sout la promesse quand l‚Äôaudio est termin√©
    const speakTextForSpeaker = async (speaker, text) => {
        try {
            const baseUrl = getTTSBaseUrlForSpeaker(speaker);
            const params = new URLSearchParams({
                text: text,
                format: "wav"
                // si besoin : speaker_id, etc.
            });

            const ttsUrl = `${baseUrl}?${params.toString()}`;

            const response = await fetch(ttsUrl);
            if (!response.ok) {
                throw new Error(`Erreur TTS (${speaker}): ${response.status}`);
            }

            const audioBlob = await response.blob();
            const audioUrl = URL.createObjectURL(audioBlob);
            stopAudioPlayback(); // √âvite tout chevauchement de son pr√©c√©dent
            const audio = new Audio(audioUrl);
            currentAudio = audio;
            currentAudioUrl = audioUrl;

            // On retourne une promesse qui se r√©sout √† la fin de la lecture ou en cas d'arr√™t manuel
            return new Promise((resolve) => {
                let settled = false;
                currentAudioResolver = () => {
                    if (settled) return;
                    settled = true;
                    resolve();
                };

                const finalizePlayback = () => {
                    if (currentAudio === audio) {
                        stopAudioPlayback();
                    } else if (currentAudioResolver) {
                        const resolver = currentAudioResolver;
                        currentAudioResolver = null;
                        resolver();
                    }
                };

                audio.onended = finalizePlayback;
                audio.onerror = (err) => {
                    console.error("Erreur lecture audio:", err);
                    finalizePlayback();
                };
                audio.onpause = () => {
                    if (!audio.ended) {
                        finalizePlayback();
                    }
                };

            // Peut √™tre bloqu√© si autoplay n'est pas autoris√©, mais comme √ßa d√©marre apr√®s un clic, √ßa passe en g√©n√©ral.
                audio.play().catch((err) => {
                    console.warn("Impossible de lancer l'audio (autoplay ?) :", err);
                    finalizePlayback();
                });
            });

        } catch (e) {
            console.error("Erreur TTS:", e);
            // On ne bloque pas la boucle si le TTS plante
            return;
        }
    };

    // --- UI ---

    const appendMessageToUI = (speaker, text) => {
        const msg_ia = document.createElement('div');
        msg_ia.style.marginBottom = "15px";
        msg_ia.style.padding = "10px";
        msg_ia.style.borderRadius = "8px";
        msg_ia.style.maxWidth = "85%";

        if (speaker === "H√¥te") {
            msg_ia.style.backgroundColor = "#e0f2fe"; // Bleu clair
            msg_ia.style.borderLeft = "4px solid #0284c7";
            msg_ia.style.marginLeft = "0";
            msg_ia.innerHTML = `<strong>üéôÔ∏è H√¥te :</strong> ${text}`;
        } else if (speaker === "Invit√©") {
            msg_ia.style.backgroundColor = "#f0fdf4"; // Vert clair
            msg_ia.style.borderLeft = "4px solid #16a34a";
            msg_ia.style.marginLeft = "auto";
            msg_ia.innerHTML = `<strong>üó£Ô∏è Invit√© :</strong> ${text}`;
        } else {
            // Pour les messages syst√®me / erreurs
            msg_ia.style.backgroundColor = "#fee2e2";
            msg_ia.style.borderLeft = "4px solid #b91c1c";
            msg_ia.style.marginLeft = "0";
            msg_ia.innerHTML = `<strong>‚ö†Ô∏è Syst√®me :</strong> ${text}`;
        }

        responseOutput.appendChild(msg_ia);
        responseOutput.scrollTop = responseOutput.scrollHeight;
    };

    // --- BOUCLE DE PODCAST ---

    const conversationLoop = async () => {
        if (!isRunning) return;

        // turnCount = nb de messages (y compris le system) d√©j√† envoy√©s au mod√®le
        const turnCount = conversationHistory.length;
        // On alterne H√¥te / Invit√© :
        // Apr√®s le system (index 0), premier tour => turnCount = 1 -> H√¥te
        // puis Invit√©, etc.
        const currentSpeaker = (turnCount % 2 !== 0) ? "H√¥te" : "Invit√©";

        try {
            const reply = await callDeepSeek(conversationHistory);

            if (!reply) {
                appendMessageToUI("Syst√®me", "Erreur de connexion √† l'IA. Arr√™t du podcast.");
                stopPodcast();
                return;
            }

            // 1. Affichage texte
            appendMessageToUI(currentSpeaker, reply);

            // 2. Lecture audio via TTS
            await speakTextForSpeaker(currentSpeaker, reply);

            // 3. Mise √† jour de l‚Äôhistorique pour DeepSeek
            conversationHistory.push({
                role: "assistant",
                content: reply
            });

            // 4. On relance la boucle si toujours en cours
            if (isRunning) {
                conversationLoop();
            }

        } catch (e) {
            console.error(e);
            appendMessageToUI("Syst√®me", "Erreur interne. Arr√™t du podcast.");
            stopPodcast();
        }
    };

    const stopPodcast = () => {
        isRunning = false;
        sendBtn.disabled = false;
        btnText.innerText = "‚öôÔ∏èLancer le Podcast";
        btnText.style.display = 'inline';
        btnLoader.style.display = 'none';
        stopAudioPlayback();
    };

    // --- GESTIONNAIRES D'√âV√âNEMENTS ---

    sendBtn.addEventListener('click', async (e) => {
        e.preventDefault();
        const text = promptInput.value.trim();

        // Si d√©j√† en cours, clic = on arr√™te
        if (isRunning) {
            stopPodcast();
            return;
        }

        if (!text) {
            promptInput.focus();
            promptInput.style.borderColor = '#ef4444';
            setTimeout(() => promptInput.style.borderColor = '', 2000);
            return;
        }

        isRunning = true;
        btnText.innerText = "‚öôÔ∏èArr√™ter le Podcast";
        btnLoader.style.display = 'block';

        responseOutput.innerHTML = "";
        responseOutput.style.display = 'block';

        const systemPrompt = `
            Tu simules un podcast entre deux personnes sur le th√®me : "${text}".

            R√¥les :
            - Interlocuteur A = H√¥te : ton calme, courtois, registre soutenu, pose des questions et relance le d√©bat.
            - Interlocuteur B = Invit√© : expert ou passionn√©, r√©pond de mani√®re pr√©cise et nuanc√©e, registre soutenu.

            STYLE OBLIGATOIRE :
            - R√©ponds TOUJOURS en fran√ßais.
            - Registre soutenu : pas d'argot, pas de verlan, vocabulaire clair et pr√©cis.
            - Dialogue naturel : chaque r√©plique doit rebondir sur la pr√©c√©dente.
            - R√©ponse tr√®s courte : 20 √† 40 mots maximum, id√©alement ~30 mots.
            - Maximum 120 caract√®res environ.
            - Ne PAS commencer par "H√¥te:" ou "Invit√©:", uniquement le texte parl√©.
            - Ne jamais conclure la discussion, toujours laisser une ouverture.

            Exemples de longueur attendue :
            - "Pourriez-vous pr√©ciser en quoi cette approche d'IA transforme concr√®tement nos pratiques quotidiennes ?"
            - "Elle structure l'apprentissage et √©vite de se disperser dans des d√©tails techniques secondaires."

            Commence par une courte phrase de l'H√¥te qui introduit le sujet.
        `;


        conversationHistory = [
            { role: "system", content: systemPrompt }
        ];

        console.log(`D√©marrage du podcast sur: ${text}`);
        conversationLoop();
    });

    if (clearBtn) {
        clearBtn.addEventListener('click', () => {
            if (isRunning) {
                stopPodcast();
            }
            promptInput.value = "";
            responseOutput.innerHTML = "";
            responseOutput.style.display = "none";
            promptInput.focus();
        });
    }

    // Entr√©e pour lancer (Shift+Entr√©e autorise un saut de ligne)
    promptInput.addEventListener('keydown', (e) => {
        if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            sendBtn.click();
        }
    });
});
