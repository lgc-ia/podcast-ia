document.addEventListener('DOMContentLoaded', (e) => {
    e.preventDefault()

    const promptInput = document.getElementById('promptInput')
    const sendBtn = document.getElementById('sendBtn')
    const clearBtn = document.getElementById('clearBtn')
    const btnText = sendBtn.querySelector('span')
    const btnLoader = document.getElementById('btnLoader')
    const responseOutput = document.getElementById('responseOutput')
    const footerYear = document.querySelector('.footer-year')
    let isHostTurn = true // l'H√¥te commence
    const MAX_TURNS_FOR_API = 10 // nb de r√©pliques max envoy√©es au mod√®le (hors message syst√®me)

    // üéöÔ∏è NEW: champs de configuration dans la page
    const situationInput = document.getElementById('situationInput')
    const hostDescInput = document.getElementById('hostDescInput')
    const guestDescInput = document.getElementById('guestDescInput')

    // üéöÔ∏è NEW: valeurs par d√©faut si l‚Äôutilisateur ne remplit rien
    const DEFAULT_SITUATION = 'podcast p√©dagogique'
    const DEFAULT_HOST_DESC =
        'un enseignant homme enthousiaste et bienveillant, ton calme, courtois, registre soutenu, qui pose des questions et relance le d√©bat'
    const DEFAULT_GUEST_DESC =
        'une enseignante femme enthousiaste et bienveillante, experte ou passionn√©e, qui r√©pond de mani√®re pr√©cise et nuanc√©e, registre soutenu'

    if (footerYear) {
        footerYear.textContent = new Date().getFullYear()
    }

    // --- CONFIGURATION ---

    // ‚ö†Ô∏è ATTENTION : En production, ne jamais laisser une cl√© API c√¥t√© client.
    // On passe d√©sormais par notre backend Vercel
    const API_URL = '/api/chat'

    // TTS : endpoints Piper HTTP
    // Tu peux inverser les URLs si tu veux H√¥te=femme, Invit√©=homme.
    const TTS_HOST_URL = 'https://ttsh.lagrandeclasse.fr/' // H√¥te -> femme
    const TTS_GUEST_URL = 'https://ttsf.lagrandeclasse.fr/' // Invit√© -> homme

    let isRunning = false // Pour arr√™ter le podcast
    let conversationHistory = [] // Historique pour le LLM
    let currentAudio = null // Audio en cours de lecture
    let currentAudioUrl = null // URL √† lib√©rer pour l'audio courant
    let currentAudioResolver = null // Permet de r√©soudre la promesse de lecture si on stoppe manuellement

    // Stoppe proprement le son en cours (si pr√©sent) et r√©sout la promesse rattach√©e
    const stopAudioPlayback = () => {
        if (currentAudio) {
            currentAudio.onended = null
            currentAudio.onerror = null
            currentAudio.onpause = null
            currentAudio.pause()
            currentAudio.currentTime = 0
        }

        if (currentAudioUrl) {
            URL.revokeObjectURL(currentAudioUrl)
        }

        currentAudio = null
        currentAudioUrl = null

        if (currentAudioResolver) {
            const resolver = currentAudioResolver
            currentAudioResolver = null
            resolver()
        }
    }

    // --- FONCTIONS IA ---

    // Ne renvoie que le message syst√®me + les X derniers messages
    const getMessagesForApi = () => {
        if (conversationHistory.length === 0) return []

        const systemMessage = conversationHistory[0] // { role: "system", ... }
        const otherMessages = conversationHistory.slice(1) // tout le reste (assistant)

        if (otherMessages.length <= MAX_TURNS_FOR_API) {
            return conversationHistory
        }

        const trimmed = otherMessages.slice(-MAX_TURNS_FOR_API)
        return [systemMessage, ...trimmed]
    }

    // Appel DeepSeek (compatible OpenAI)
    // Appel via backend /api/chat
    const callDeepSeek = async (messages) => {
        try {
            const response = await fetch(API_URL, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ messages }), // on envoie juste messages
            })

            if (!response.ok) {
                throw new Error(`Erreur API: ${response.status}`)
            }

            const data = await response.json()
            return data.choices[0].message.content
        } catch (error) {
            console.error("Erreur lors de l'appel DeepSeek:", error)
            return null
        }
    }

    // --- FONCTIONS TTS ---

    // D√©coupe un texte en petits blocs pour le TTS (phrases + longueur max)
    const splitIntoChunks = (text, maxLen = 220) => {
        // D√©coupage grossier en phrases sur . ! ?
        const sentences = text.match(/[^.!?]+[.!?]?/g) || [text]

        const chunks = []
        let current = ''

        for (const raw of sentences) {
            const s = raw.trim()
            if (!s) continue

            if ((current + ' ' + s).length > maxLen) {
                if (current) chunks.push(current.trim())
                // Si une seule phrase d√©passe maxLen, on la pousse telle quelle
                if (s.length > maxLen) {
                    chunks.push(s)
                    current = ''
                } else {
                    current = s
                }
            } else {
                current = current ? current + ' ' + s : s
            }
        }

        if (current) chunks.push(current.trim())
        return chunks
    }

    // R√©cup√®re l‚ÄôURL de base TTS en fonction de l‚Äôinterlocuteur
    const getTTSBaseUrlForSpeaker = (speaker) => {
        if (speaker === 'H√¥te') return TTS_HOST_URL
        if (speaker === 'Invit√©') return TTS_GUEST_URL
        // fallback : H√¥te
        return TTS_HOST_URL
    }

    // Joue un seul "chunk" TTS pour un speaker
    const playTTSChunkForSpeaker = async (speaker, text) => {
        try {
            const baseUrl = getTTSBaseUrlForSpeaker(speaker)
            const params = new URLSearchParams({
                text: text,
                format: 'wav',
                // si besoin : speaker_id, etc.
            })

            const ttsUrl = `${baseUrl}?${params.toString()}`

            const response = await fetch(ttsUrl)
            if (!response.ok) {
                throw new Error(`Erreur TTS (${speaker}): ${response.status}`)
            }

            const audioBlob = await response.blob()
            const audioUrl = URL.createObjectURL(audioBlob)
            stopAudioPlayback() // √âvite tout chevauchement de son pr√©c√©dent
            const audio = new Audio(audioUrl)
            currentAudio = audio
            currentAudioUrl = audioUrl

            // On retourne une promesse qui se r√©sout √† la fin de la lecture ou en cas d'arr√™t manuel
            return new Promise((resolve) => {
                let settled = false
                currentAudioResolver = () => {
                    if (settled) return
                    settled = true
                    resolve()
                }

                const finalizePlayback = () => {
                    if (currentAudio === audio) {
                        stopAudioPlayback()
                    } else if (currentAudioResolver) {
                        const resolver = currentAudioResolver
                        currentAudioResolver = null
                        resolver()
                    }
                }

                audio.onended = finalizePlayback
                audio.onerror = (err) => {
                    console.error('Erreur lecture audio:', err)
                    finalizePlayback()
                }
                audio.onpause = () => {
                    if (!audio.ended) {
                        finalizePlayback()
                    }
                }

                // Peut √™tre bloqu√© si autoplay n'est pas autoris√©, mais comme √ßa d√©marre apr√®s un clic, √ßa passe en g√©n√©ral.
                audio.play().catch((err) => {
                    console.warn("Impossible de lancer l'audio (autoplay ?) :", err)
                    finalizePlayback()
                })
            })
        } catch (e) {
            console.error('Erreur TTS:', e)
            // On ne bloque pas la boucle si le TTS plante
            return
        }
    }

    // Appelle le TTS en mode chunk√© : plusieurs petits appels s√©quentiels
    const speakTextForSpeaker = async (speaker, fullText) => {
        const chunks = splitIntoChunks(fullText, 220)
        console.log(`TTS ${speaker} chunks:`, chunks)

        for (const chunk of chunks) {
            if (!isRunning) {
                // Si le podcast est arr√™t√© entre deux chunks, on sort proprement
                break
            }
            await playTTSChunkForSpeaker(speaker, chunk)
        }
    }

    // --- UI ---

    const appendMessageToUI = (speaker, text) => {
        const msg_ia = document.createElement('div')
        msg_ia.style.marginBottom = '15px'
        msg_ia.style.padding = '10px'
        msg_ia.style.borderRadius = '8px'
        msg_ia.style.maxWidth = '85%'

        if (speaker === 'H√¥te') {
            msg_ia.style.backgroundColor = '#e0f2fe' // Bleu clair
            msg_ia.style.borderLeft = '4px solid #0284c7'
            msg_ia.style.marginLeft = '0'
            msg_ia.innerHTML = `<strong>üéôÔ∏è H√¥te :</strong> ${text}`
        } else if (speaker === 'Invit√©') {
            msg_ia.style.backgroundColor = '#f0fdf4' // Vert clair
            msg_ia.style.borderLeft = '4px solid #16a34a'
            msg_ia.style.marginLeft = 'auto'
            msg_ia.innerHTML = `<strong>üó£Ô∏è Invit√© :</strong> ${text}`
        } else {
            // Pour les messages syst√®me / erreurs
            msg_ia.style.backgroundColor = '#fee2e2'
            msg_ia.style.borderLeft = '4px solid #b91c1c'
            msg_ia.style.marginLeft = '0'
            msg_ia.innerHTML = `<strong>‚ö†Ô∏è Syst√®me :</strong> ${text}`
        }

        responseOutput.appendChild(msg_ia)
        responseOutput.scrollTop = responseOutput.scrollHeight
    }

    // --- BOUCLE DE PODCAST ---

    const conversationLoop = async () => {
        if (!isRunning) return

        // turnCount = nb de messages (y compris le system) d√©j√† envoy√©s au mod√®le
        const turnCount = conversationHistory.length
        // On alterne H√¥te / Invit√© :
        // Apr√®s le system (index 0), premier tour => turnCount = 1 -> H√¥te
        // puis Invit√©, etc.
        const currentSpeaker = isHostTurn ? 'H√¥te' : 'Invit√©'

        try {
            const messagesForApi = getMessagesForApi()
            const reply = await callDeepSeek(messagesForApi)

            if (!reply) {
                appendMessageToUI('Syst√®me', "Erreur de connexion √† l'IA. Arr√™t du podcast.")
                stopPodcast()
                return
            }

            // 1. Affichage texte
            appendMessageToUI(currentSpeaker, reply)

            // 2. Lecture audio via TTS (chunk√©e)
            await speakTextForSpeaker(currentSpeaker, reply)

            // 3. Mise √† jour de l‚Äôhistorique pour DeepSeek
            conversationHistory.push({
                role: 'assistant',
                content: reply,
            })

            // üîÅ Toggle du speaker
            isHostTurn = !isHostTurn

            // 4. On relance la boucle si toujours en cours
            if (isRunning) {
                conversationLoop()
            }
        } catch (e) {
            console.error(e)
            appendMessageToUI('Syst√®me', 'Erreur interne. Arr√™t du podcast.')
            stopPodcast()
        }
    }

    const stopPodcast = () => {
        isRunning = false
        sendBtn.disabled = false
        btnText.innerText = '‚öôÔ∏èLancer le Podcast'
        btnText.style.display = 'inline'
        btnLoader.style.display = 'none'
        stopAudioPlayback()
    }

    // --- GESTIONNAIRES D'√âV√âNEMENTS ---

    sendBtn.addEventListener('click', async (e) => {
        e.preventDefault()
        const text = promptInput.value.trim()

        // Si d√©j√† en cours, clic = on arr√™te
        if (isRunning) {
            stopPodcast()
            isHostTurn = true // üîÅ Reset pour la prochaine fois
            return
        }

        if (!text) {
            promptInput.focus()
            promptInput.style.borderColor = '#ef4444'
            setTimeout(() => (promptInput.style.borderColor = ''), 2000)
            return
        }

        // üéöÔ∏è NEW: on lit les 3 champs utilisateur avec fallback sur les valeurs par d√©faut
        const situation = (situationInput?.value || DEFAULT_SITUATION).trim() || DEFAULT_SITUATION
        const hostDesc = (hostDescInput?.value || DEFAULT_HOST_DESC).trim() || DEFAULT_HOST_DESC
        const guestDesc = (guestDescInput?.value || DEFAULT_GUEST_DESC).trim() || DEFAULT_GUEST_DESC

        // üö® Ici on d√©marre : on reset le speaker AVANT de lancer
        isHostTurn = true

        isRunning = true
        btnText.innerText = '‚öôÔ∏èArr√™ter le Podcast'
        btnLoader.style.display = 'block'

        responseOutput.innerHTML = ''
        responseOutput.style.display = 'block'

        // üéöÔ∏è NEW: prompt dynamique avec situation + descriptions
        const systemPrompt = `
            Tu simules ${situation} entre deux personnes sur le th√®me : "${text}".

            R√¥les :
            - Interlocuteur A = H√¥te : ${hostDesc}.
            - Interlocuteur B = Invit√© : ${guestDesc}.

            STYLE OBLIGATOIRE :
            - R√©ponds TOUJOURS en fran√ßais.
            - Registre soutenu : pas d'argot, pas de verlan, vocabulaire clair et pr√©cis.
            - Dialogue naturel : chaque r√©plique doit rebondir sur la pr√©c√©dente.
            - R√©ponse tr√®s courte : 20 √† 40 mots maximum, id√©alement ~30 mots.
            - Maximum 120 caract√®res environ.
            - Ne PAS commencer par "H√¥te:" ou "Invit√©:", uniquement le texte parl√©.
            - Ne jamais conclure la discussion, toujours laisser une ouverture.

            Exemples de longueur attendue :
            - "Pourriez-vous pr√©ciser en quoi cette approche d'IA transforme concr√®tement nos pratiques quotidiennes ?"
            - "Elle structure l'apprentissage et √©vite de se disperser dans des d√©tails techniques secondaires."

            Commence par une courte phrase de l'H√¥te qui introduit le sujet.
        `

        conversationHistory = [{ role: 'system', content: systemPrompt }]

        console.log(`D√©marrage du podcast sur: ${text}`)
        conversationLoop()
    })

    if (clearBtn) {
        clearBtn.addEventListener('click', () => {
            if (isRunning) {
                stopPodcast()
            }
            promptInput.value = ''
            responseOutput.innerHTML = ''
            responseOutput.style.display = 'none'
            promptInput.focus()
        })
    }

    // Entr√©e pour lancer (Shift+Entr√©e autorise un saut de ligne)
    promptInput.addEventListener('keydown', (e) => {
        if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault()
            sendBtn.click()
        }
    })
})
